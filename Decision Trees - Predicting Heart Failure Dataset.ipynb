{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19c01794",
   "metadata": {},
   "source": [
    "# Ensemble Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac883a",
   "metadata": {},
   "source": [
    "## B. Importing Libraries & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "932e736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caaefaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"/Users/steffipoliwoda/Desktop/heartFailure.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b174257",
   "metadata": {},
   "source": [
    "## C. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f91ce58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes','ejection_fraction','high_blood_pressure','platelets', 'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f9d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "x = df[feature_columns]\n",
    "y = df['DEATH_EVENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20962c1",
   "metadata": {},
   "source": [
    "## D. Splitting Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f779f06",
   "metadata": {},
   "source": [
    "We will divide the dataset into a training set and a test set using the function train_test_split() and by passing three parameters: \n",
    "- features\n",
    "- target\n",
    "- test_set size\n",
    "- Optional: random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d183d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f494fa2",
   "metadata": {},
   "source": [
    "The Dataset is split into two parts with a ratio of 80:20. It means that 80% data will be used for model training and 20% for model testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c58e405",
   "metadata": {},
   "source": [
    "## E. Model Development & Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884faa6d",
   "metadata": {},
   "source": [
    "### 1. DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea30877",
   "metadata": {},
   "source": [
    "We will first specify the hyperparameters of the base estimator (decision tree classifier) with the entropy or information gain as the splitting criterion. We will define the hyperparameters for the bagging classifier. We will pass the base estimator object to the classifier as a hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f719aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the base classifiers \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f887c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the hyperparameters for the base estimator (decision tree) and initialise the model\n",
    "# entropy or information gain as splitting criterion\n",
    "dt_params = { 'criterion': 'entropy', 'random_state': 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a4066b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(**dt_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b909fdeb",
   "metadata": {},
   "source": [
    "We will fit the decision tree model to the training data to compare prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65a3bf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the decision tree model to the training data\n",
    "dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6e6933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the predicting accuracy for training data\n",
    "dt_preds_train = dt.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c699af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the predicting accuracy for test data\n",
    "dt_preds_test = dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1bd140a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "> Accuracy on training data = 1.0000\n",
      "> Accuracy on validation data = 0.7333\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree:\\n> Accuracy on training data = {:.4f}\\n> Accuracy on validation data = {:.4f}'.format( accuracy_score(y_true=y_train, y_pred=dt_preds_train), accuracy_score(y_true=y_test, y_pred=dt_preds_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac87398",
   "metadata": {},
   "source": [
    "- The decision tree predicts all the class labels of the training examples correctly.\n",
    "- The lower test accuracy indicates high variance of the model.\n",
    "- High variance means that the decision tree is overfitting to the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad92984a",
   "metadata": {},
   "source": [
    "### 2. Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd82a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the bagging classifiers \n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc768f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing ensemble classifier \n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea3ec7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the hyperparameters for the BaggingClassifier\n",
    "bc_params = { 'base_estimator': dt, 'n_estimators': 50, 'max_samples': 0.5, 'random_state': 11, 'n_jobs': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d56d79a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the base estimator object to the clssifier as hyperparameter\n",
    "bc = BaggingClassifier(**bc_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d935be53",
   "metadata": {},
   "source": [
    "We will fit the bagging classifier model to the training data and calculate the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ac3904b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy',\n",
       "                                                        random_state=11),\n",
       "                  max_samples=0.5, n_estimators=50, n_jobs=-1, random_state=11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the bagging classifier model to the training data\n",
    "bc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5241854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the predicting accuracy for training data\n",
    "bc_preds_train = bc.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb3864e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the predicting accuracy for test data\n",
    "bc_preds_test = bc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ab70129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier:\n",
      "> Accuracy on training data = 0.9498\n",
      "> Accuracy on validation data = 0.8500\n"
     ]
    }
   ],
   "source": [
    "print('Bagging Classifier:\\n> Accuracy on training data = {:.4f}\\n> Accuracy on validation data = {:.4f}'.format( accuracy_score(y_true=y_train, y_pred=bc_preds_train), accuracy_score(y_true=y_test, y_pred=bc_preds_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9940cc5",
   "metadata": {},
   "source": [
    "- The Decision Tree Classifier has a higher accuracy on the training data than the Bagging Classifier.\n",
    "- The Bagging Classifier has a higher accuracy on the test data than the Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4371dcf5",
   "metadata": {},
   "source": [
    "### 3. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "892dda68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf50b8",
   "metadata": {},
   "source": [
    "We will specify the hyperparameters and initialize the model. We will use entropy as the splitting criterion for the decision trees in a forest comprising 100 trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98f96953",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = { 'n_estimators': 100, 'criterion': 'entropy', 'max_features': 0.5, 'min_samples_leaf': 10, 'random_state': 11, 'n_jobs': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d333a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(**rf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d6523",
   "metadata": {},
   "source": [
    "We will fit the Random Forest classifier model to the training data and calculate the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b424c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_features=0.5,\n",
       "                       min_samples_leaf=10, n_jobs=-1, random_state=11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ce1ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_preds_train = rf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dafacd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_preds_test = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ace5e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "> Accuracy on training data = 0.8745\n",
      "> Accuracy on validation data = 0.9000\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest:\\n> Accuracy on training data = {:.4f}\\n> Accuracy on validation data = {:.4f}'.format( accuracy_score(y_true=y_train, y_pred=rf_preds_train), accuracy_score(y_true=y_test, y_pred=rf_preds_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e494a36",
   "metadata": {},
   "source": [
    "- The accuracy of the Random Forest on the test set is comprated to the bagging classifier is almost the same. - Even though the Bagging Classifier has higher accuracy on the training dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
